{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7000210,"sourceType":"datasetVersion","datasetId":4024114}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T12:49:26.381774Z","iopub.execute_input":"2025-03-22T12:49:26.382049Z","iopub.status.idle":"2025-03-22T12:49:29.723782Z","shell.execute_reply.started":"2025-03-22T12:49:26.382028Z","shell.execute_reply":"2025-03-22T12:49:29.722684Z"}},"outputs":[{"name":"stdout","text":"Looking in indexes: https://download.pytorch.org/whl/cu126\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchvision) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchvision) (2024.2.0)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport torch, os\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, models","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-22T12:49:29.725225Z","iopub.execute_input":"2025-03-22T12:49:29.725528Z","iopub.status.idle":"2025-03-22T12:49:29.729812Z","shell.execute_reply.started":"2025-03-22T12:49:29.725497Z","shell.execute_reply":"2025-03-22T12:49:29.729078Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"data_transforms = {\n    'train': transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.RandomRotation(20),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5], [0.5])\n    ]),\n    'test': transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5], [0.5])\n    ]),\n    'val': transforms.Compose([\n        transforms.Resize((256, 256)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.5], [0.5])\n    ]),\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T12:49:29.731315Z","iopub.execute_input":"2025-03-22T12:49:29.731601Z","iopub.status.idle":"2025-03-22T12:49:29.747564Z","shell.execute_reply.started":"2025-03-22T12:49:29.731571Z","shell.execute_reply":"2025-03-22T12:49:29.746775Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"data_dir = '/kaggle/input/fundus-pytorch'\nimage_datasets = {x: datasets.ImageFolder(\n    root=f\"{data_dir}/{x}\",\n    transform=data_transforms[x]\n) for x in ['train', 'test', 'val']}\n\ndataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True) for x in ['train', 'test', 'val']}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T12:49:29.748432Z","iopub.execute_input":"2025-03-22T12:49:29.748888Z","iopub.status.idle":"2025-03-22T12:49:43.619561Z","shell.execute_reply.started":"2025-03-22T12:49:29.748858Z","shell.execute_reply":"2025-03-22T12:49:43.618906Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class GlaucomaCNN(nn.Module):\n    def __init__(self):\n        super(GlaucomaCNN, self).__init__()\n        self.conv_layers = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2)\n        )\n        self.fc_layers = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(128 * 32 * 32, 512),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(512, 2)\n        )\n    \n    def forward(self, x):\n        x = self.conv_layers(x)\n        x = self.fc_layers(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T12:49:43.620269Z","iopub.execute_input":"2025-03-22T12:49:43.620503Z","iopub.status.idle":"2025-03-22T12:49:43.626291Z","shell.execute_reply.started":"2025-03-22T12:49:43.620484Z","shell.execute_reply":"2025-03-22T12:49:43.625338Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = GlaucomaCNN()\n\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n    model = nn.DataParallel(model)\n\nmodel = model.to(device)\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T12:49:43.627591Z","iopub.execute_input":"2025-03-22T12:49:43.627833Z","iopub.status.idle":"2025-03-22T12:49:44.305948Z","shell.execute_reply.started":"2025-03-22T12:49:43.627813Z","shell.execute_reply":"2025-03-22T12:49:44.305082Z"}},"outputs":[{"name":"stdout","text":"Using 2 GPUs!\ncuda\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T12:49:44.306843Z","iopub.execute_input":"2025-03-22T12:49:44.307091Z","iopub.status.idle":"2025-03-22T12:49:44.311471Z","shell.execute_reply.started":"2025-03-22T12:49:44.307072Z","shell.execute_reply":"2025-03-22T12:49:44.310839Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Training loop\ndef train_model(model, dataloaders, criterion, optimizer, num_epochs=10):\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        \n        print(f\"Epoch {epoch+1}/{num_epochs}\")\n        print(\"-\" * 30)\n        \n        for batch_idx, (inputs, labels) in enumerate(dataloaders['train']):\n            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n            \n            if (batch_idx + 1) % 10 == 0:\n                print(f\"Batch {batch_idx+1}/{len(dataloaders['train'])} | Loss: {loss.item():.4f}\")\n        \n        epoch_loss = running_loss / len(dataloaders['train'])\n        epoch_acc = 100. * correct / total\n        print(f\"Epoch {epoch+1} Loss: {epoch_loss:.4f} | Accuracy: {epoch_acc:.2f}%\\n\")\n        \n        # Validation phase\n        model.eval()\n        val_loss = 0.0\n        val_correct = 0\n        val_total = 0\n        with torch.no_grad():\n            for inputs, labels in dataloaders['val']:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                _, predicted = outputs.max(1)\n                val_total += labels.size(0)\n                val_correct += predicted.eq(labels).sum().item()\n        \n        val_loss /= len(dataloaders['val'])\n        val_acc = 100. * val_correct / val_total\n        print(f\"Validation Loss: {val_loss:.4f} | Validation Accuracy: {val_acc:.2f}%\\n\")\n\ntrain_model(model, dataloaders, criterion, optimizer, num_epochs=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T12:49:48.045168Z","iopub.execute_input":"2025-03-22T12:49:48.045461Z","iopub.status.idle":"2025-03-22T15:45:56.808874Z","shell.execute_reply.started":"2025-03-22T12:49:48.045438Z","shell.execute_reply":"2025-03-22T15:45:56.808009Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n------------------------------\nBatch 10/270 | Loss: 0.6362\nBatch 20/270 | Loss: 0.6852\nBatch 30/270 | Loss: 0.6668\nBatch 40/270 | Loss: 0.5900\nBatch 50/270 | Loss: 0.6612\nBatch 60/270 | Loss: 0.6277\nBatch 70/270 | Loss: 0.6657\nBatch 80/270 | Loss: 0.7120\nBatch 90/270 | Loss: 0.6441\nBatch 100/270 | Loss: 0.5697\nBatch 110/270 | Loss: 0.6047\nBatch 120/270 | Loss: 0.6178\nBatch 130/270 | Loss: 0.6786\nBatch 140/270 | Loss: 0.6799\nBatch 150/270 | Loss: 0.6373\nBatch 160/270 | Loss: 0.6271\nBatch 170/270 | Loss: 0.6065\nBatch 180/270 | Loss: 0.6601\nBatch 190/270 | Loss: 0.5628\nBatch 200/270 | Loss: 0.5826\nBatch 210/270 | Loss: 0.5817\nBatch 220/270 | Loss: 0.6135\nBatch 230/270 | Loss: 0.7217\nBatch 240/270 | Loss: 0.6900\nBatch 250/270 | Loss: 0.5840\nBatch 260/270 | Loss: 0.3508\nBatch 270/270 | Loss: 0.6153\nEpoch 1 Loss: 0.6314 | Accuracy: 67.96%\n\nValidation Loss: 0.5816 | Validation Accuracy: 71.32%\n\nEpoch 2/50\n------------------------------\nBatch 10/270 | Loss: 0.5257\nBatch 20/270 | Loss: 0.5712\nBatch 30/270 | Loss: 0.5129\nBatch 40/270 | Loss: 0.4741\nBatch 50/270 | Loss: 0.6616\nBatch 60/270 | Loss: 0.5299\nBatch 70/270 | Loss: 0.5583\nBatch 80/270 | Loss: 0.7111\nBatch 90/270 | Loss: 0.4969\nBatch 100/270 | Loss: 0.6153\nBatch 110/270 | Loss: 0.4331\nBatch 120/270 | Loss: 0.6061\nBatch 130/270 | Loss: 0.5929\nBatch 140/270 | Loss: 0.4709\nBatch 150/270 | Loss: 0.5068\nBatch 160/270 | Loss: 0.5050\nBatch 170/270 | Loss: 0.5791\nBatch 180/270 | Loss: 0.6618\nBatch 190/270 | Loss: 0.4232\nBatch 200/270 | Loss: 0.8116\nBatch 210/270 | Loss: 0.5896\nBatch 220/270 | Loss: 0.5642\nBatch 230/270 | Loss: 0.7004\nBatch 240/270 | Loss: 0.6007\nBatch 250/270 | Loss: 0.6472\nBatch 260/270 | Loss: 0.5242\nBatch 270/270 | Loss: 0.5729\nEpoch 2 Loss: 0.5788 | Accuracy: 71.20%\n\nValidation Loss: 0.5384 | Validation Accuracy: 74.42%\n\nEpoch 3/50\n------------------------------\nBatch 10/270 | Loss: 0.6696\nBatch 20/270 | Loss: 0.7405\nBatch 30/270 | Loss: 0.5596\nBatch 40/270 | Loss: 0.7591\nBatch 50/270 | Loss: 0.6012\nBatch 60/270 | Loss: 0.5907\nBatch 70/270 | Loss: 0.7069\nBatch 80/270 | Loss: 0.4617\nBatch 90/270 | Loss: 0.6492\nBatch 100/270 | Loss: 0.5268\nBatch 110/270 | Loss: 0.4990\nBatch 120/270 | Loss: 0.6267\nBatch 130/270 | Loss: 0.5171\nBatch 140/270 | Loss: 0.5470\nBatch 150/270 | Loss: 0.5019\nBatch 160/270 | Loss: 0.5985\nBatch 170/270 | Loss: 0.5692\nBatch 180/270 | Loss: 0.5261\nBatch 190/270 | Loss: 0.7065\nBatch 200/270 | Loss: 0.7100\nBatch 210/270 | Loss: 0.4754\nBatch 220/270 | Loss: 0.4622\nBatch 230/270 | Loss: 0.4098\nBatch 240/270 | Loss: 0.5726\nBatch 250/270 | Loss: 0.5688\nBatch 260/270 | Loss: 0.4483\nBatch 270/270 | Loss: 0.6371\nEpoch 3 Loss: 0.5482 | Accuracy: 73.10%\n\nValidation Loss: 0.5207 | Validation Accuracy: 74.94%\n\nEpoch 4/50\n------------------------------\nBatch 10/270 | Loss: 0.5483\nBatch 20/270 | Loss: 0.3514\nBatch 30/270 | Loss: 0.4638\nBatch 40/270 | Loss: 0.4313\nBatch 50/270 | Loss: 0.6442\nBatch 60/270 | Loss: 0.3863\nBatch 70/270 | Loss: 0.7310\nBatch 80/270 | Loss: 0.4140\nBatch 90/270 | Loss: 0.6831\nBatch 100/270 | Loss: 0.5593\nBatch 110/270 | Loss: 0.6181\nBatch 120/270 | Loss: 0.6402\nBatch 130/270 | Loss: 0.4877\nBatch 140/270 | Loss: 0.5043\nBatch 150/270 | Loss: 0.5341\nBatch 160/270 | Loss: 0.5037\nBatch 170/270 | Loss: 0.4935\nBatch 180/270 | Loss: 0.7153\nBatch 190/270 | Loss: 0.4264\nBatch 200/270 | Loss: 0.4943\nBatch 210/270 | Loss: 0.5507\nBatch 220/270 | Loss: 0.4455\nBatch 230/270 | Loss: 0.4619\nBatch 240/270 | Loss: 0.5288\nBatch 250/270 | Loss: 0.5007\nBatch 260/270 | Loss: 0.4359\nBatch 270/270 | Loss: 0.3998\nEpoch 4 Loss: 0.5323 | Accuracy: 73.85%\n\nValidation Loss: 0.5044 | Validation Accuracy: 75.73%\n\nEpoch 5/50\n------------------------------\nBatch 10/270 | Loss: 0.5812\nBatch 20/270 | Loss: 0.6275\nBatch 30/270 | Loss: 0.5322\nBatch 40/270 | Loss: 0.3627\nBatch 50/270 | Loss: 0.5246\nBatch 60/270 | Loss: 0.4390\nBatch 70/270 | Loss: 0.6663\nBatch 80/270 | Loss: 0.4174\nBatch 90/270 | Loss: 0.4678\nBatch 100/270 | Loss: 0.5693\nBatch 110/270 | Loss: 0.3704\nBatch 120/270 | Loss: 0.5306\nBatch 130/270 | Loss: 0.5172\nBatch 140/270 | Loss: 0.6241\nBatch 150/270 | Loss: 0.4033\nBatch 160/270 | Loss: 0.5669\nBatch 170/270 | Loss: 0.5067\nBatch 180/270 | Loss: 0.3836\nBatch 190/270 | Loss: 0.4764\nBatch 200/270 | Loss: 0.5030\nBatch 210/270 | Loss: 0.5098\nBatch 220/270 | Loss: 0.3526\nBatch 230/270 | Loss: 0.5878\nBatch 240/270 | Loss: 0.5603\nBatch 250/270 | Loss: 0.5389\nBatch 260/270 | Loss: 0.4668\nBatch 270/270 | Loss: 0.5221\nEpoch 5 Loss: 0.5157 | Accuracy: 75.36%\n\nValidation Loss: 0.4864 | Validation Accuracy: 76.49%\n\nEpoch 6/50\n------------------------------\nBatch 10/270 | Loss: 0.4279\nBatch 20/270 | Loss: 0.4984\nBatch 30/270 | Loss: 0.5100\nBatch 40/270 | Loss: 0.4443\nBatch 50/270 | Loss: 0.7274\nBatch 60/270 | Loss: 0.4836\nBatch 70/270 | Loss: 0.3773\nBatch 80/270 | Loss: 0.3771\nBatch 90/270 | Loss: 0.4116\nBatch 100/270 | Loss: 0.4311\nBatch 110/270 | Loss: 0.4825\nBatch 120/270 | Loss: 0.5828\nBatch 130/270 | Loss: 0.3910\nBatch 140/270 | Loss: 0.4068\nBatch 150/270 | Loss: 0.3897\nBatch 160/270 | Loss: 0.5655\nBatch 170/270 | Loss: 0.4871\nBatch 180/270 | Loss: 0.5373\nBatch 190/270 | Loss: 0.3651\nBatch 200/270 | Loss: 0.5445\nBatch 210/270 | Loss: 0.5272\nBatch 220/270 | Loss: 0.5590\nBatch 230/270 | Loss: 0.4139\nBatch 240/270 | Loss: 0.5250\nBatch 250/270 | Loss: 0.5552\nBatch 260/270 | Loss: 0.6125\nBatch 270/270 | Loss: 0.5928\nEpoch 6 Loss: 0.5031 | Accuracy: 76.35%\n\nValidation Loss: 0.4638 | Validation Accuracy: 78.67%\n\nEpoch 7/50\n------------------------------\nBatch 10/270 | Loss: 0.4561\nBatch 20/270 | Loss: 0.5939\nBatch 30/270 | Loss: 0.5544\nBatch 40/270 | Loss: 0.4975\nBatch 50/270 | Loss: 0.4994\nBatch 60/270 | Loss: 0.5206\nBatch 70/270 | Loss: 0.5807\nBatch 80/270 | Loss: 0.4957\nBatch 90/270 | Loss: 0.4650\nBatch 100/270 | Loss: 0.4133\nBatch 110/270 | Loss: 0.4293\nBatch 120/270 | Loss: 0.4730\nBatch 130/270 | Loss: 0.4676\nBatch 140/270 | Loss: 0.6220\nBatch 150/270 | Loss: 0.3851\nBatch 160/270 | Loss: 0.5547\nBatch 170/270 | Loss: 0.6823\nBatch 180/270 | Loss: 0.5647\nBatch 190/270 | Loss: 0.5866\nBatch 200/270 | Loss: 0.4144\nBatch 210/270 | Loss: 0.4112\nBatch 220/270 | Loss: 0.5583\nBatch 230/270 | Loss: 0.5704\nBatch 240/270 | Loss: 0.4754\nBatch 250/270 | Loss: 0.4113\nBatch 260/270 | Loss: 0.4919\nBatch 270/270 | Loss: 0.4592\nEpoch 7 Loss: 0.4888 | Accuracy: 77.26%\n\nValidation Loss: 0.4654 | Validation Accuracy: 77.40%\n\nEpoch 8/50\n------------------------------\nBatch 10/270 | Loss: 0.4706\nBatch 20/270 | Loss: 0.5455\nBatch 30/270 | Loss: 0.4339\nBatch 40/270 | Loss: 0.5238\nBatch 50/270 | Loss: 0.4796\nBatch 60/270 | Loss: 0.3396\nBatch 70/270 | Loss: 0.4454\nBatch 80/270 | Loss: 0.4703\nBatch 90/270 | Loss: 0.3536\nBatch 100/270 | Loss: 0.5170\nBatch 110/270 | Loss: 0.4161\nBatch 120/270 | Loss: 0.3644\nBatch 130/270 | Loss: 0.6001\nBatch 140/270 | Loss: 0.3875\nBatch 150/270 | Loss: 0.5014\nBatch 160/270 | Loss: 0.4350\nBatch 170/270 | Loss: 0.5602\nBatch 180/270 | Loss: 0.4937\nBatch 190/270 | Loss: 0.4751\nBatch 200/270 | Loss: 0.5977\nBatch 210/270 | Loss: 0.4275\nBatch 220/270 | Loss: 0.3619\nBatch 230/270 | Loss: 0.4415\nBatch 240/270 | Loss: 0.3893\nBatch 250/270 | Loss: 0.4634\nBatch 260/270 | Loss: 0.4399\nBatch 270/270 | Loss: 0.2896\nEpoch 8 Loss: 0.4769 | Accuracy: 77.65%\n\nValidation Loss: 0.4477 | Validation Accuracy: 80.77%\n\nEpoch 9/50\n------------------------------\nBatch 10/270 | Loss: 0.3867\nBatch 20/270 | Loss: 0.4932\nBatch 30/270 | Loss: 0.4886\nBatch 40/270 | Loss: 0.5370\nBatch 50/270 | Loss: 0.4601\nBatch 60/270 | Loss: 0.3311\nBatch 70/270 | Loss: 0.5720\nBatch 80/270 | Loss: 0.3994\nBatch 90/270 | Loss: 0.3949\nBatch 100/270 | Loss: 0.6654\nBatch 110/270 | Loss: 0.5302\nBatch 120/270 | Loss: 0.6213\nBatch 130/270 | Loss: 0.5664\nBatch 140/270 | Loss: 0.4238\nBatch 150/270 | Loss: 0.6563\nBatch 160/270 | Loss: 0.4413\nBatch 170/270 | Loss: 0.3648\nBatch 180/270 | Loss: 0.5666\nBatch 190/270 | Loss: 0.4687\nBatch 200/270 | Loss: 0.5047\nBatch 210/270 | Loss: 0.5888\nBatch 220/270 | Loss: 0.6281\nBatch 230/270 | Loss: 0.5069\nBatch 240/270 | Loss: 0.4827\nBatch 250/270 | Loss: 0.3777\nBatch 260/270 | Loss: 0.2755\nBatch 270/270 | Loss: 0.3891\nEpoch 9 Loss: 0.4650 | Accuracy: 78.49%\n\nValidation Loss: 0.4212 | Validation Accuracy: 81.33%\n\nEpoch 10/50\n------------------------------\nBatch 10/270 | Loss: 0.4548\nBatch 20/270 | Loss: 0.3058\nBatch 30/270 | Loss: 0.3851\nBatch 40/270 | Loss: 0.4349\nBatch 50/270 | Loss: 0.8021\nBatch 60/270 | Loss: 0.3886\nBatch 70/270 | Loss: 0.4607\nBatch 80/270 | Loss: 0.5204\nBatch 90/270 | Loss: 0.5312\nBatch 100/270 | Loss: 0.3126\nBatch 110/270 | Loss: 0.4479\nBatch 120/270 | Loss: 0.4220\nBatch 130/270 | Loss: 0.5008\nBatch 140/270 | Loss: 0.4405\nBatch 150/270 | Loss: 0.5928\nBatch 160/270 | Loss: 0.3677\nBatch 170/270 | Loss: 0.3511\nBatch 180/270 | Loss: 0.4446\nBatch 190/270 | Loss: 0.4920\nBatch 200/270 | Loss: 0.4139\nBatch 210/270 | Loss: 0.5246\nBatch 220/270 | Loss: 0.3408\nBatch 230/270 | Loss: 0.2469\nBatch 240/270 | Loss: 0.5679\nBatch 250/270 | Loss: 0.5765\nBatch 260/270 | Loss: 0.5043\nBatch 270/270 | Loss: 0.2574\nEpoch 10 Loss: 0.4492 | Accuracy: 79.34%\n\nValidation Loss: 0.4201 | Validation Accuracy: 80.39%\n\nEpoch 11/50\n------------------------------\nBatch 10/270 | Loss: 0.3194\nBatch 20/270 | Loss: 0.3573\nBatch 30/270 | Loss: 0.3866\nBatch 40/270 | Loss: 0.5969\nBatch 50/270 | Loss: 0.3785\nBatch 60/270 | Loss: 0.3771\nBatch 70/270 | Loss: 0.4974\nBatch 80/270 | Loss: 0.3147\nBatch 90/270 | Loss: 0.3871\nBatch 100/270 | Loss: 0.3203\nBatch 110/270 | Loss: 0.3518\nBatch 120/270 | Loss: 0.3576\nBatch 130/270 | Loss: 0.4397\nBatch 140/270 | Loss: 0.2968\nBatch 150/270 | Loss: 0.3332\nBatch 160/270 | Loss: 0.3416\nBatch 170/270 | Loss: 0.3749\nBatch 180/270 | Loss: 0.4494\nBatch 190/270 | Loss: 0.4002\nBatch 200/270 | Loss: 0.3893\nBatch 210/270 | Loss: 0.3879\nBatch 220/270 | Loss: 0.4407\nBatch 230/270 | Loss: 0.4525\nBatch 240/270 | Loss: 0.5205\nBatch 250/270 | Loss: 0.4060\nBatch 260/270 | Loss: 0.3169\nBatch 270/270 | Loss: 0.4753\nEpoch 11 Loss: 0.4294 | Accuracy: 80.86%\n\nValidation Loss: 0.3801 | Validation Accuracy: 83.50%\n\nEpoch 12/50\n------------------------------\nBatch 10/270 | Loss: 0.4695\nBatch 20/270 | Loss: 0.3656\nBatch 30/270 | Loss: 0.4727\nBatch 40/270 | Loss: 0.6228\nBatch 50/270 | Loss: 0.5588\nBatch 60/270 | Loss: 0.4359\nBatch 70/270 | Loss: 0.2378\nBatch 80/270 | Loss: 0.4643\nBatch 90/270 | Loss: 0.1654\nBatch 100/270 | Loss: 0.3886\nBatch 110/270 | Loss: 0.5388\nBatch 120/270 | Loss: 0.5179\nBatch 130/270 | Loss: 0.4617\nBatch 140/270 | Loss: 0.4840\nBatch 150/270 | Loss: 0.3615\nBatch 160/270 | Loss: 0.4020\nBatch 170/270 | Loss: 0.2893\nBatch 180/270 | Loss: 0.4513\nBatch 190/270 | Loss: 0.3158\nBatch 200/270 | Loss: 0.3204\nBatch 210/270 | Loss: 0.3585\nBatch 220/270 | Loss: 0.3998\nBatch 230/270 | Loss: 0.4517\nBatch 240/270 | Loss: 0.4058\nBatch 250/270 | Loss: 0.3217\nBatch 260/270 | Loss: 0.3889\nBatch 270/270 | Loss: 0.4120\nEpoch 12 Loss: 0.4204 | Accuracy: 81.39%\n\nValidation Loss: 0.3912 | Validation Accuracy: 82.41%\n\nEpoch 13/50\n------------------------------\nBatch 10/270 | Loss: 0.4305\nBatch 20/270 | Loss: 0.5978\nBatch 30/270 | Loss: 0.4362\nBatch 40/270 | Loss: 0.4520\nBatch 50/270 | Loss: 0.4138\nBatch 60/270 | Loss: 0.2572\nBatch 70/270 | Loss: 0.4622\nBatch 80/270 | Loss: 0.4101\nBatch 90/270 | Loss: 0.3039\nBatch 100/270 | Loss: 0.3345\nBatch 110/270 | Loss: 0.3991\nBatch 120/270 | Loss: 0.3387\nBatch 130/270 | Loss: 0.6215\nBatch 140/270 | Loss: 0.4145\nBatch 150/270 | Loss: 0.4431\nBatch 160/270 | Loss: 0.3355\nBatch 170/270 | Loss: 0.5561\nBatch 180/270 | Loss: 0.4370\nBatch 190/270 | Loss: 0.5428\nBatch 200/270 | Loss: 0.4542\nBatch 210/270 | Loss: 0.3081\nBatch 220/270 | Loss: 0.3641\nBatch 230/270 | Loss: 0.4741\nBatch 240/270 | Loss: 0.4496\nBatch 250/270 | Loss: 0.7696\nBatch 260/270 | Loss: 0.3909\nBatch 270/270 | Loss: 0.2265\nEpoch 13 Loss: 0.4040 | Accuracy: 81.81%\n\nValidation Loss: 0.3701 | Validation Accuracy: 83.28%\n\nEpoch 14/50\n------------------------------\nBatch 10/270 | Loss: 0.3635\nBatch 20/270 | Loss: 0.3917\nBatch 30/270 | Loss: 0.4724\nBatch 40/270 | Loss: 0.4825\nBatch 50/270 | Loss: 0.3891\nBatch 60/270 | Loss: 0.3503\nBatch 70/270 | Loss: 0.4630\nBatch 80/270 | Loss: 0.3615\nBatch 90/270 | Loss: 0.2927\nBatch 100/270 | Loss: 0.3269\nBatch 110/270 | Loss: 0.3197\nBatch 120/270 | Loss: 0.3517\nBatch 130/270 | Loss: 0.5489\nBatch 140/270 | Loss: 0.5152\nBatch 150/270 | Loss: 0.7368\nBatch 160/270 | Loss: 0.2715\nBatch 170/270 | Loss: 0.6051\nBatch 180/270 | Loss: 0.2912\nBatch 190/270 | Loss: 0.5048\nBatch 200/270 | Loss: 0.2953\nBatch 210/270 | Loss: 0.3186\nBatch 220/270 | Loss: 0.3865\nBatch 230/270 | Loss: 0.2257\nBatch 240/270 | Loss: 0.3739\nBatch 250/270 | Loss: 0.3941\nBatch 260/270 | Loss: 0.3482\nBatch 270/270 | Loss: 0.4332\nEpoch 14 Loss: 0.4015 | Accuracy: 82.17%\n\nValidation Loss: 0.3783 | Validation Accuracy: 83.23%\n\nEpoch 15/50\n------------------------------\nBatch 10/270 | Loss: 0.6490\nBatch 20/270 | Loss: 0.4046\nBatch 30/270 | Loss: 0.3497\nBatch 40/270 | Loss: 0.2443\nBatch 50/270 | Loss: 0.3875\nBatch 60/270 | Loss: 0.4703\nBatch 70/270 | Loss: 0.3352\nBatch 80/270 | Loss: 0.6197\nBatch 90/270 | Loss: 0.4680\nBatch 100/270 | Loss: 0.2620\nBatch 110/270 | Loss: 0.3767\nBatch 120/270 | Loss: 0.6220\nBatch 130/270 | Loss: 0.3253\nBatch 140/270 | Loss: 0.4410\nBatch 150/270 | Loss: 0.2583\nBatch 160/270 | Loss: 0.2875\nBatch 170/270 | Loss: 0.3272\nBatch 180/270 | Loss: 0.3067\nBatch 190/270 | Loss: 0.4950\nBatch 200/270 | Loss: 0.4204\nBatch 210/270 | Loss: 0.4670\nBatch 220/270 | Loss: 0.4401\nBatch 230/270 | Loss: 0.5173\nBatch 240/270 | Loss: 0.3470\nBatch 250/270 | Loss: 0.4624\nBatch 260/270 | Loss: 0.2708\nBatch 270/270 | Loss: 0.5357\nEpoch 15 Loss: 0.3999 | Accuracy: 82.19%\n\nValidation Loss: 0.3471 | Validation Accuracy: 84.77%\n\nEpoch 16/50\n------------------------------\nBatch 10/270 | Loss: 0.3476\nBatch 20/270 | Loss: 0.5681\nBatch 30/270 | Loss: 0.3434\nBatch 40/270 | Loss: 0.4712\nBatch 50/270 | Loss: 0.2672\nBatch 60/270 | Loss: 0.2253\nBatch 70/270 | Loss: 0.4025\nBatch 80/270 | Loss: 0.4809\nBatch 90/270 | Loss: 0.4300\nBatch 100/270 | Loss: 0.5080\nBatch 110/270 | Loss: 0.3156\nBatch 120/270 | Loss: 0.3311\nBatch 130/270 | Loss: 0.2988\nBatch 140/270 | Loss: 0.3531\nBatch 150/270 | Loss: 0.6674\nBatch 160/270 | Loss: 0.4027\nBatch 170/270 | Loss: 0.3355\nBatch 180/270 | Loss: 0.2883\nBatch 190/270 | Loss: 0.5871\nBatch 200/270 | Loss: 0.3636\nBatch 210/270 | Loss: 0.3547\nBatch 220/270 | Loss: 0.4426\nBatch 230/270 | Loss: 0.4517\nBatch 240/270 | Loss: 0.2531\nBatch 250/270 | Loss: 0.3597\nBatch 260/270 | Loss: 0.4897\nBatch 270/270 | Loss: 0.3715\nEpoch 16 Loss: 0.3854 | Accuracy: 83.46%\n\nValidation Loss: 0.3408 | Validation Accuracy: 85.12%\n\nEpoch 17/50\n------------------------------\nBatch 10/270 | Loss: 0.3814\nBatch 20/270 | Loss: 0.3312\nBatch 30/270 | Loss: 0.4366\nBatch 40/270 | Loss: 0.3996\nBatch 50/270 | Loss: 0.1543\nBatch 60/270 | Loss: 0.3557\nBatch 70/270 | Loss: 0.3148\nBatch 80/270 | Loss: 0.6927\nBatch 90/270 | Loss: 0.3795\nBatch 100/270 | Loss: 0.3402\nBatch 110/270 | Loss: 0.2511\nBatch 120/270 | Loss: 0.3846\nBatch 130/270 | Loss: 0.4473\nBatch 140/270 | Loss: 0.4935\nBatch 150/270 | Loss: 0.3082\nBatch 160/270 | Loss: 0.6150\nBatch 170/270 | Loss: 0.3744\nBatch 180/270 | Loss: 0.4403\nBatch 190/270 | Loss: 0.4136\nBatch 200/270 | Loss: 0.7746\nBatch 210/270 | Loss: 0.3737\nBatch 220/270 | Loss: 0.2973\nBatch 230/270 | Loss: 0.3016\nBatch 240/270 | Loss: 0.3514\nBatch 250/270 | Loss: 0.1879\nBatch 260/270 | Loss: 0.3287\nBatch 270/270 | Loss: 0.4005\nEpoch 17 Loss: 0.3730 | Accuracy: 83.24%\n\nValidation Loss: 0.3353 | Validation Accuracy: 85.21%\n\nEpoch 18/50\n------------------------------\nBatch 10/270 | Loss: 0.2381\nBatch 20/270 | Loss: 0.4453\nBatch 30/270 | Loss: 0.1871\nBatch 40/270 | Loss: 0.4689\nBatch 50/270 | Loss: 0.1827\nBatch 60/270 | Loss: 0.4326\nBatch 70/270 | Loss: 0.3430\nBatch 80/270 | Loss: 0.4606\nBatch 90/270 | Loss: 0.3049\nBatch 100/270 | Loss: 0.4669\nBatch 110/270 | Loss: 0.3599\nBatch 120/270 | Loss: 0.2206\nBatch 130/270 | Loss: 0.5307\nBatch 140/270 | Loss: 0.4920\nBatch 150/270 | Loss: 0.3984\nBatch 160/270 | Loss: 0.3296\nBatch 170/270 | Loss: 0.3469\nBatch 180/270 | Loss: 0.3671\nBatch 190/270 | Loss: 0.3282\nBatch 200/270 | Loss: 0.3381\nBatch 210/270 | Loss: 0.3746\nBatch 220/270 | Loss: 0.3270\nBatch 230/270 | Loss: 0.2527\nBatch 240/270 | Loss: 0.5405\nBatch 250/270 | Loss: 0.3174\nBatch 260/270 | Loss: 0.2151\nBatch 270/270 | Loss: 0.2681\nEpoch 18 Loss: 0.3803 | Accuracy: 83.71%\n\nValidation Loss: 0.3157 | Validation Accuracy: 86.58%\n\nEpoch 19/50\n------------------------------\nBatch 10/270 | Loss: 0.3114\nBatch 20/270 | Loss: 0.3354\nBatch 30/270 | Loss: 0.3458\nBatch 40/270 | Loss: 0.3060\nBatch 50/270 | Loss: 0.3081\nBatch 60/270 | Loss: 0.3151\nBatch 70/270 | Loss: 0.4700\nBatch 80/270 | Loss: 0.2095\nBatch 90/270 | Loss: 0.2412\nBatch 100/270 | Loss: 0.2825\nBatch 110/270 | Loss: 0.3961\nBatch 120/270 | Loss: 0.4137\nBatch 130/270 | Loss: 0.3204\nBatch 140/270 | Loss: 0.2468\nBatch 150/270 | Loss: 0.4055\nBatch 160/270 | Loss: 0.3503\nBatch 170/270 | Loss: 0.2906\nBatch 180/270 | Loss: 0.3808\nBatch 190/270 | Loss: 0.2330\nBatch 200/270 | Loss: 0.2900\nBatch 210/270 | Loss: 0.3026\nBatch 220/270 | Loss: 0.5693\nBatch 230/270 | Loss: 0.2795\nBatch 240/270 | Loss: 0.4624\nBatch 250/270 | Loss: 0.4474\nBatch 260/270 | Loss: 0.4035\nBatch 270/270 | Loss: 0.4612\nEpoch 19 Loss: 0.3631 | Accuracy: 83.92%\n\nValidation Loss: 0.3280 | Validation Accuracy: 85.89%\n\nEpoch 20/50\n------------------------------\nBatch 10/270 | Loss: 0.2570\nBatch 20/270 | Loss: 0.2079\nBatch 30/270 | Loss: 0.2921\nBatch 40/270 | Loss: 0.5807\nBatch 50/270 | Loss: 0.2772\nBatch 60/270 | Loss: 0.2087\nBatch 70/270 | Loss: 0.2010\nBatch 80/270 | Loss: 0.1966\nBatch 90/270 | Loss: 0.2461\nBatch 100/270 | Loss: 0.3445\nBatch 110/270 | Loss: 0.4213\nBatch 120/270 | Loss: 0.3317\nBatch 130/270 | Loss: 0.2826\nBatch 140/270 | Loss: 0.3546\nBatch 150/270 | Loss: 0.3846\nBatch 160/270 | Loss: 0.4954\nBatch 170/270 | Loss: 0.3739\nBatch 180/270 | Loss: 0.5757\nBatch 190/270 | Loss: 0.3469\nBatch 200/270 | Loss: 0.3536\nBatch 210/270 | Loss: 0.4570\nBatch 220/270 | Loss: 0.1571\nBatch 230/270 | Loss: 0.2807\nBatch 240/270 | Loss: 0.3380\nBatch 250/270 | Loss: 0.3751\nBatch 260/270 | Loss: 0.4040\nBatch 270/270 | Loss: 0.3571\nEpoch 20 Loss: 0.3666 | Accuracy: 84.02%\n\nValidation Loss: 0.3372 | Validation Accuracy: 85.00%\n\nEpoch 21/50\n------------------------------\nBatch 10/270 | Loss: 0.4845\nBatch 20/270 | Loss: 0.3296\nBatch 30/270 | Loss: 0.4490\nBatch 40/270 | Loss: 0.3254\nBatch 50/270 | Loss: 0.2092\nBatch 60/270 | Loss: 0.3997\nBatch 70/270 | Loss: 0.4625\nBatch 80/270 | Loss: 0.2448\nBatch 90/270 | Loss: 0.3777\nBatch 100/270 | Loss: 0.1902\nBatch 110/270 | Loss: 0.4874\nBatch 120/270 | Loss: 0.4027\nBatch 130/270 | Loss: 0.3259\nBatch 140/270 | Loss: 0.3781\nBatch 150/270 | Loss: 0.4579\nBatch 160/270 | Loss: 0.4407\nBatch 170/270 | Loss: 0.3202\nBatch 180/270 | Loss: 0.4008\nBatch 190/270 | Loss: 0.3086\nBatch 200/270 | Loss: 0.3780\nBatch 210/270 | Loss: 0.3973\nBatch 220/270 | Loss: 0.6043\nBatch 230/270 | Loss: 0.4424\nBatch 240/270 | Loss: 0.4406\nBatch 250/270 | Loss: 0.3847\nBatch 260/270 | Loss: 0.3712\nBatch 270/270 | Loss: 0.2471\nEpoch 21 Loss: 0.3609 | Accuracy: 84.11%\n\nValidation Loss: 0.3173 | Validation Accuracy: 86.79%\n\nEpoch 22/50\n------------------------------\nBatch 10/270 | Loss: 0.3624\nBatch 20/270 | Loss: 0.3894\nBatch 30/270 | Loss: 0.4926\nBatch 40/270 | Loss: 0.3678\nBatch 50/270 | Loss: 0.2755\nBatch 60/270 | Loss: 0.3442\nBatch 70/270 | Loss: 0.3262\nBatch 80/270 | Loss: 0.3005\nBatch 90/270 | Loss: 0.4111\nBatch 100/270 | Loss: 0.2576\nBatch 110/270 | Loss: 0.2566\nBatch 120/270 | Loss: 0.3774\nBatch 130/270 | Loss: 0.2764\nBatch 140/270 | Loss: 0.3202\nBatch 150/270 | Loss: 0.2608\nBatch 160/270 | Loss: 0.3870\nBatch 170/270 | Loss: 0.1890\nBatch 180/270 | Loss: 0.3403\nBatch 190/270 | Loss: 0.3639\nBatch 200/270 | Loss: 0.3488\nBatch 210/270 | Loss: 0.3625\nBatch 220/270 | Loss: 0.3479\nBatch 230/270 | Loss: 0.3044\nBatch 240/270 | Loss: 0.4207\nBatch 250/270 | Loss: 0.2130\nBatch 260/270 | Loss: 0.3156\nBatch 270/270 | Loss: 0.3355\nEpoch 22 Loss: 0.3493 | Accuracy: 84.72%\n\nValidation Loss: 0.3307 | Validation Accuracy: 85.51%\n\nEpoch 23/50\n------------------------------\nBatch 10/270 | Loss: 0.3596\nBatch 20/270 | Loss: 0.4346\nBatch 30/270 | Loss: 0.3090\nBatch 40/270 | Loss: 0.3922\nBatch 50/270 | Loss: 0.4763\nBatch 60/270 | Loss: 0.4229\nBatch 70/270 | Loss: 0.2484\nBatch 80/270 | Loss: 0.6647\nBatch 90/270 | Loss: 0.4665\nBatch 100/270 | Loss: 0.3032\nBatch 110/270 | Loss: 0.2650\nBatch 120/270 | Loss: 0.3375\nBatch 130/270 | Loss: 0.3811\nBatch 140/270 | Loss: 0.2694\nBatch 150/270 | Loss: 0.1764\nBatch 160/270 | Loss: 0.2441\nBatch 170/270 | Loss: 0.2243\nBatch 180/270 | Loss: 0.3943\nBatch 190/270 | Loss: 0.4174\nBatch 200/270 | Loss: 0.4463\nBatch 210/270 | Loss: 0.2576\nBatch 220/270 | Loss: 0.3452\nBatch 230/270 | Loss: 0.2361\nBatch 240/270 | Loss: 0.4974\nBatch 250/270 | Loss: 0.2566\nBatch 260/270 | Loss: 0.2357\nBatch 270/270 | Loss: 0.3636\nEpoch 23 Loss: 0.3485 | Accuracy: 85.12%\n\nValidation Loss: 0.3078 | Validation Accuracy: 86.74%\n\nEpoch 24/50\n------------------------------\nBatch 10/270 | Loss: 0.2613\nBatch 20/270 | Loss: 0.2925\nBatch 30/270 | Loss: 0.3304\nBatch 40/270 | Loss: 0.3727\nBatch 50/270 | Loss: 0.3460\nBatch 60/270 | Loss: 0.3093\nBatch 70/270 | Loss: 0.2025\nBatch 80/270 | Loss: 0.4480\nBatch 90/270 | Loss: 0.1938\nBatch 100/270 | Loss: 0.4082\nBatch 110/270 | Loss: 0.3147\nBatch 120/270 | Loss: 0.3085\nBatch 130/270 | Loss: 0.3068\nBatch 140/270 | Loss: 0.1652\nBatch 150/270 | Loss: 0.3205\nBatch 160/270 | Loss: 0.2730\nBatch 170/270 | Loss: 0.3871\nBatch 180/270 | Loss: 0.3379\nBatch 190/270 | Loss: 0.3410\nBatch 200/270 | Loss: 0.3503\nBatch 210/270 | Loss: 0.3140\nBatch 220/270 | Loss: 0.3366\nBatch 230/270 | Loss: 0.2609\nBatch 240/270 | Loss: 0.3045\nBatch 250/270 | Loss: 0.4979\nBatch 260/270 | Loss: 0.3725\nBatch 270/270 | Loss: 0.8412\nEpoch 24 Loss: 0.3466 | Accuracy: 84.70%\n\nValidation Loss: 0.3236 | Validation Accuracy: 86.11%\n\nEpoch 25/50\n------------------------------\nBatch 10/270 | Loss: 0.2756\nBatch 20/270 | Loss: 0.5033\nBatch 30/270 | Loss: 0.2530\nBatch 40/270 | Loss: 0.5462\nBatch 50/270 | Loss: 0.3099\nBatch 60/270 | Loss: 0.3921\nBatch 70/270 | Loss: 0.1960\nBatch 80/270 | Loss: 0.3145\nBatch 90/270 | Loss: 0.3420\nBatch 100/270 | Loss: 0.2547\nBatch 110/270 | Loss: 0.3927\nBatch 120/270 | Loss: 0.3003\nBatch 130/270 | Loss: 0.4728\nBatch 140/270 | Loss: 0.2402\nBatch 150/270 | Loss: 0.3429\nBatch 160/270 | Loss: 0.3305\nBatch 170/270 | Loss: 0.3624\nBatch 180/270 | Loss: 0.2334\nBatch 190/270 | Loss: 0.2112\nBatch 200/270 | Loss: 0.2808\nBatch 210/270 | Loss: 0.3268\nBatch 220/270 | Loss: 0.2453\nBatch 230/270 | Loss: 0.3169\nBatch 240/270 | Loss: 0.3693\nBatch 250/270 | Loss: 0.2059\nBatch 260/270 | Loss: 0.3977\nBatch 270/270 | Loss: 0.1766\nEpoch 25 Loss: 0.3408 | Accuracy: 85.16%\n\nValidation Loss: 0.3270 | Validation Accuracy: 85.12%\n\nEpoch 26/50\n------------------------------\nBatch 10/270 | Loss: 0.2026\nBatch 20/270 | Loss: 0.2657\nBatch 30/270 | Loss: 0.2378\nBatch 40/270 | Loss: 0.2655\nBatch 50/270 | Loss: 0.6319\nBatch 60/270 | Loss: 0.3077\nBatch 70/270 | Loss: 0.2415\nBatch 80/270 | Loss: 0.2618\nBatch 90/270 | Loss: 0.3059\nBatch 100/270 | Loss: 0.2854\nBatch 110/270 | Loss: 0.3427\nBatch 120/270 | Loss: 0.3043\nBatch 130/270 | Loss: 0.3444\nBatch 140/270 | Loss: 0.4164\nBatch 150/270 | Loss: 0.2823\nBatch 160/270 | Loss: 0.3806\nBatch 170/270 | Loss: 0.3778\nBatch 180/270 | Loss: 0.4810\nBatch 190/270 | Loss: 0.3381\nBatch 200/270 | Loss: 0.2930\nBatch 210/270 | Loss: 0.5926\nBatch 220/270 | Loss: 0.2182\nBatch 230/270 | Loss: 0.3468\nBatch 240/270 | Loss: 0.5007\nBatch 250/270 | Loss: 0.1856\nBatch 260/270 | Loss: 0.4960\nBatch 270/270 | Loss: 0.0629\nEpoch 26 Loss: 0.3358 | Accuracy: 85.31%\n\nValidation Loss: 0.2897 | Validation Accuracy: 87.23%\n\nEpoch 27/50\n------------------------------\nBatch 10/270 | Loss: 0.2474\nBatch 20/270 | Loss: 0.2535\nBatch 30/270 | Loss: 0.3026\nBatch 40/270 | Loss: 0.3894\nBatch 50/270 | Loss: 0.3926\nBatch 60/270 | Loss: 0.2458\nBatch 70/270 | Loss: 0.3051\nBatch 80/270 | Loss: 0.2826\nBatch 90/270 | Loss: 0.3583\nBatch 100/270 | Loss: 0.6293\nBatch 110/270 | Loss: 0.2124\nBatch 120/270 | Loss: 0.3449\nBatch 130/270 | Loss: 0.2863\nBatch 140/270 | Loss: 0.4338\nBatch 150/270 | Loss: 0.3268\nBatch 160/270 | Loss: 0.3249\nBatch 170/270 | Loss: 0.3149\nBatch 180/270 | Loss: 0.3718\nBatch 190/270 | Loss: 0.2637\nBatch 200/270 | Loss: 0.5670\nBatch 210/270 | Loss: 0.4496\nBatch 220/270 | Loss: 0.3652\nBatch 230/270 | Loss: 0.4048\nBatch 240/270 | Loss: 0.2144\nBatch 250/270 | Loss: 0.3476\nBatch 260/270 | Loss: 0.3606\nBatch 270/270 | Loss: 0.4235\nEpoch 27 Loss: 0.3365 | Accuracy: 85.52%\n\nValidation Loss: 0.3066 | Validation Accuracy: 86.95%\n\nEpoch 28/50\n------------------------------\nBatch 10/270 | Loss: 0.3701\nBatch 20/270 | Loss: 0.1921\nBatch 30/270 | Loss: 0.2994\nBatch 40/270 | Loss: 0.1845\nBatch 50/270 | Loss: 0.1789\nBatch 60/270 | Loss: 0.3711\nBatch 70/270 | Loss: 0.4499\nBatch 80/270 | Loss: 0.2307\nBatch 90/270 | Loss: 0.3827\nBatch 100/270 | Loss: 0.3026\nBatch 110/270 | Loss: 0.2434\nBatch 120/270 | Loss: 0.3249\nBatch 130/270 | Loss: 0.2504\nBatch 140/270 | Loss: 0.2243\nBatch 150/270 | Loss: 0.1476\nBatch 160/270 | Loss: 0.4008\nBatch 170/270 | Loss: 0.3598\nBatch 180/270 | Loss: 0.3799\nBatch 190/270 | Loss: 0.6341\nBatch 200/270 | Loss: 0.2464\nBatch 210/270 | Loss: 0.2661\nBatch 220/270 | Loss: 0.3239\nBatch 230/270 | Loss: 0.1803\nBatch 240/270 | Loss: 0.2672\nBatch 250/270 | Loss: 0.2374\nBatch 260/270 | Loss: 0.2866\nBatch 270/270 | Loss: 0.3685\nEpoch 28 Loss: 0.3301 | Accuracy: 86.14%\n\nValidation Loss: 0.3164 | Validation Accuracy: 85.99%\n\nEpoch 29/50\n------------------------------\nBatch 10/270 | Loss: 0.2843\nBatch 20/270 | Loss: 0.2961\nBatch 30/270 | Loss: 0.3028\nBatch 40/270 | Loss: 0.1123\nBatch 50/270 | Loss: 0.2792\nBatch 60/270 | Loss: 0.3496\nBatch 70/270 | Loss: 0.3736\nBatch 80/270 | Loss: 0.3994\nBatch 90/270 | Loss: 0.3785\nBatch 100/270 | Loss: 0.2324\nBatch 110/270 | Loss: 0.2442\nBatch 120/270 | Loss: 0.2115\nBatch 130/270 | Loss: 0.5135\nBatch 140/270 | Loss: 0.2108\nBatch 150/270 | Loss: 0.2638\nBatch 160/270 | Loss: 0.2000\nBatch 170/270 | Loss: 0.3688\nBatch 180/270 | Loss: 0.4895\nBatch 190/270 | Loss: 0.3000\nBatch 200/270 | Loss: 0.3422\nBatch 210/270 | Loss: 0.4872\nBatch 220/270 | Loss: 0.3387\nBatch 230/270 | Loss: 0.2769\nBatch 240/270 | Loss: 0.2927\nBatch 250/270 | Loss: 0.2062\nBatch 260/270 | Loss: 0.1296\nBatch 270/270 | Loss: 0.2414\nEpoch 29 Loss: 0.3259 | Accuracy: 85.74%\n\nValidation Loss: 0.2740 | Validation Accuracy: 88.43%\n\nEpoch 30/50\n------------------------------\nBatch 10/270 | Loss: 0.3203\nBatch 20/270 | Loss: 0.3896\nBatch 30/270 | Loss: 0.3063\nBatch 40/270 | Loss: 0.2694\nBatch 50/270 | Loss: 0.3172\nBatch 60/270 | Loss: 0.4847\nBatch 70/270 | Loss: 0.2446\nBatch 80/270 | Loss: 0.1723\nBatch 90/270 | Loss: 0.3520\nBatch 100/270 | Loss: 0.3548\nBatch 110/270 | Loss: 0.2265\nBatch 120/270 | Loss: 0.3948\nBatch 130/270 | Loss: 0.2019\nBatch 140/270 | Loss: 0.2757\nBatch 150/270 | Loss: 0.3338\nBatch 160/270 | Loss: 0.4501\nBatch 170/270 | Loss: 0.7007\nBatch 180/270 | Loss: 0.4700\nBatch 190/270 | Loss: 0.3635\nBatch 200/270 | Loss: 0.5717\nBatch 210/270 | Loss: 0.3116\nBatch 220/270 | Loss: 0.4059\nBatch 230/270 | Loss: 0.3009\nBatch 240/270 | Loss: 0.4424\nBatch 250/270 | Loss: 0.2688\nBatch 260/270 | Loss: 0.2231\nBatch 270/270 | Loss: 0.1123\nEpoch 30 Loss: 0.3252 | Accuracy: 85.84%\n\nValidation Loss: 0.2853 | Validation Accuracy: 87.63%\n\nEpoch 31/50\n------------------------------\nBatch 10/270 | Loss: 0.1950\nBatch 20/270 | Loss: 0.2707\nBatch 30/270 | Loss: 0.3980\nBatch 40/270 | Loss: 0.3401\nBatch 50/270 | Loss: 0.2463\nBatch 60/270 | Loss: 0.3251\nBatch 70/270 | Loss: 0.4740\nBatch 80/270 | Loss: 0.3812\nBatch 90/270 | Loss: 0.5154\nBatch 100/270 | Loss: 0.3729\nBatch 110/270 | Loss: 0.4525\nBatch 120/270 | Loss: 0.3155\nBatch 130/270 | Loss: 0.3436\nBatch 140/270 | Loss: 0.2712\nBatch 150/270 | Loss: 0.3376\nBatch 160/270 | Loss: 0.2653\nBatch 170/270 | Loss: 0.3030\nBatch 180/270 | Loss: 0.3837\nBatch 190/270 | Loss: 0.3412\nBatch 200/270 | Loss: 0.3676\nBatch 210/270 | Loss: 0.2088\nBatch 220/270 | Loss: 0.2206\nBatch 230/270 | Loss: 0.2028\nBatch 240/270 | Loss: 0.4512\nBatch 250/270 | Loss: 0.5762\nBatch 260/270 | Loss: 0.4077\nBatch 270/270 | Loss: 0.2719\nEpoch 31 Loss: 0.3162 | Accuracy: 86.14%\n\nValidation Loss: 0.2692 | Validation Accuracy: 88.53%\n\nEpoch 32/50\n------------------------------\nBatch 10/270 | Loss: 0.2646\nBatch 20/270 | Loss: 0.3758\nBatch 30/270 | Loss: 0.1999\nBatch 40/270 | Loss: 0.2177\nBatch 50/270 | Loss: 0.2310\nBatch 60/270 | Loss: 0.2626\nBatch 70/270 | Loss: 0.1392\nBatch 80/270 | Loss: 0.4040\nBatch 90/270 | Loss: 0.3464\nBatch 100/270 | Loss: 0.3568\nBatch 110/270 | Loss: 0.2983\nBatch 120/270 | Loss: 0.5311\nBatch 130/270 | Loss: 0.1463\nBatch 140/270 | Loss: 0.2328\nBatch 150/270 | Loss: 0.2600\nBatch 160/270 | Loss: 0.2494\nBatch 170/270 | Loss: 0.2393\nBatch 180/270 | Loss: 0.2934\nBatch 190/270 | Loss: 0.2984\nBatch 200/270 | Loss: 0.4053\nBatch 210/270 | Loss: 0.3236\nBatch 220/270 | Loss: 0.2005\nBatch 230/270 | Loss: 0.1485\nBatch 240/270 | Loss: 0.3470\nBatch 250/270 | Loss: 0.2841\nBatch 260/270 | Loss: 0.3650\nBatch 270/270 | Loss: 0.4212\nEpoch 32 Loss: 0.3085 | Accuracy: 87.01%\n\nValidation Loss: 0.2732 | Validation Accuracy: 88.22%\n\nEpoch 33/50\n------------------------------\nBatch 10/270 | Loss: 0.1502\nBatch 20/270 | Loss: 0.1729\nBatch 30/270 | Loss: 0.2265\nBatch 40/270 | Loss: 0.4535\nBatch 50/270 | Loss: 0.3589\nBatch 60/270 | Loss: 0.0948\nBatch 70/270 | Loss: 0.2234\nBatch 80/270 | Loss: 0.1789\nBatch 90/270 | Loss: 0.3748\nBatch 100/270 | Loss: 0.3436\nBatch 110/270 | Loss: 0.2255\nBatch 120/270 | Loss: 0.3495\nBatch 130/270 | Loss: 0.2055\nBatch 140/270 | Loss: 0.2005\nBatch 150/270 | Loss: 0.2096\nBatch 160/270 | Loss: 0.2818\nBatch 170/270 | Loss: 0.4802\nBatch 180/270 | Loss: 0.4104\nBatch 190/270 | Loss: 0.3296\nBatch 200/270 | Loss: 0.2854\nBatch 210/270 | Loss: 0.4276\nBatch 220/270 | Loss: 0.1742\nBatch 230/270 | Loss: 0.3424\nBatch 240/270 | Loss: 0.6441\nBatch 250/270 | Loss: 0.5238\nBatch 260/270 | Loss: 0.2476\nBatch 270/270 | Loss: 0.3222\nEpoch 33 Loss: 0.3124 | Accuracy: 86.47%\n\nValidation Loss: 0.2563 | Validation Accuracy: 89.14%\n\nEpoch 34/50\n------------------------------\nBatch 10/270 | Loss: 0.4667\nBatch 20/270 | Loss: 0.4947\nBatch 30/270 | Loss: 0.3277\nBatch 40/270 | Loss: 0.1744\nBatch 50/270 | Loss: 0.1781\nBatch 60/270 | Loss: 0.3520\nBatch 70/270 | Loss: 0.1692\nBatch 80/270 | Loss: 0.4080\nBatch 90/270 | Loss: 0.1665\nBatch 100/270 | Loss: 0.3593\nBatch 110/270 | Loss: 0.3507\nBatch 120/270 | Loss: 0.2106\nBatch 130/270 | Loss: 0.1556\nBatch 140/270 | Loss: 0.4694\nBatch 150/270 | Loss: 0.2624\nBatch 160/270 | Loss: 0.2000\nBatch 170/270 | Loss: 0.2609\nBatch 180/270 | Loss: 0.2019\nBatch 190/270 | Loss: 0.3571\nBatch 200/270 | Loss: 0.3347\nBatch 210/270 | Loss: 0.3053\nBatch 220/270 | Loss: 0.3984\nBatch 230/270 | Loss: 0.3622\nBatch 240/270 | Loss: 0.2002\nBatch 250/270 | Loss: 0.3817\nBatch 260/270 | Loss: 0.3738\nBatch 270/270 | Loss: 0.2723\nEpoch 34 Loss: 0.3071 | Accuracy: 86.92%\n\nValidation Loss: 0.2685 | Validation Accuracy: 88.46%\n\nEpoch 35/50\n------------------------------\nBatch 10/270 | Loss: 0.3219\nBatch 20/270 | Loss: 0.3202\nBatch 30/270 | Loss: 0.2052\nBatch 40/270 | Loss: 0.2445\nBatch 50/270 | Loss: 0.2590\nBatch 60/270 | Loss: 0.4458\nBatch 70/270 | Loss: 0.3358\nBatch 80/270 | Loss: 0.2400\nBatch 90/270 | Loss: 0.1982\nBatch 100/270 | Loss: 0.3753\nBatch 110/270 | Loss: 0.2925\nBatch 120/270 | Loss: 0.2968\nBatch 130/270 | Loss: 0.2309\nBatch 140/270 | Loss: 0.3819\nBatch 150/270 | Loss: 0.3304\nBatch 160/270 | Loss: 0.3109\nBatch 170/270 | Loss: 0.1219\nBatch 180/270 | Loss: 0.4534\nBatch 190/270 | Loss: 0.1814\nBatch 200/270 | Loss: 0.3863\nBatch 210/270 | Loss: 0.5771\nBatch 220/270 | Loss: 0.2166\nBatch 230/270 | Loss: 0.1954\nBatch 240/270 | Loss: 0.3423\nBatch 250/270 | Loss: 0.2436\nBatch 260/270 | Loss: 0.3178\nBatch 270/270 | Loss: 0.2750\nEpoch 35 Loss: 0.3022 | Accuracy: 87.14%\n\nValidation Loss: 0.2549 | Validation Accuracy: 89.07%\n\nEpoch 36/50\n------------------------------\nBatch 10/270 | Loss: 0.2546\nBatch 20/270 | Loss: 0.4444\nBatch 30/270 | Loss: 0.2998\nBatch 40/270 | Loss: 0.2807\nBatch 50/270 | Loss: 0.3989\nBatch 60/270 | Loss: 0.2474\nBatch 70/270 | Loss: 0.3805\nBatch 80/270 | Loss: 0.3462\nBatch 90/270 | Loss: 0.3178\nBatch 100/270 | Loss: 0.4364\nBatch 110/270 | Loss: 0.3282\nBatch 120/270 | Loss: 0.2708\nBatch 130/270 | Loss: 0.3038\nBatch 140/270 | Loss: 0.2679\nBatch 150/270 | Loss: 0.1940\nBatch 160/270 | Loss: 0.2189\nBatch 170/270 | Loss: 0.4295\nBatch 180/270 | Loss: 0.1298\nBatch 190/270 | Loss: 0.3380\nBatch 200/270 | Loss: 0.2681\nBatch 210/270 | Loss: 0.3527\nBatch 220/270 | Loss: 0.2867\nBatch 230/270 | Loss: 0.3254\nBatch 240/270 | Loss: 0.3598\nBatch 250/270 | Loss: 0.2111\nBatch 260/270 | Loss: 0.3178\nBatch 270/270 | Loss: 0.3956\nEpoch 36 Loss: 0.3043 | Accuracy: 86.97%\n\nValidation Loss: 0.2616 | Validation Accuracy: 88.92%\n\nEpoch 37/50\n------------------------------\nBatch 10/270 | Loss: 0.1690\nBatch 20/270 | Loss: 0.3082\nBatch 30/270 | Loss: 0.2902\nBatch 40/270 | Loss: 0.2681\nBatch 50/270 | Loss: 0.3770\nBatch 60/270 | Loss: 0.2063\nBatch 70/270 | Loss: 0.5694\nBatch 80/270 | Loss: 0.1839\nBatch 90/270 | Loss: 0.2652\nBatch 100/270 | Loss: 0.4522\nBatch 110/270 | Loss: 0.0860\nBatch 120/270 | Loss: 0.3320\nBatch 130/270 | Loss: 0.1950\nBatch 140/270 | Loss: 0.4267\nBatch 150/270 | Loss: 0.2258\nBatch 160/270 | Loss: 0.3806\nBatch 170/270 | Loss: 0.2769\nBatch 180/270 | Loss: 0.3462\nBatch 190/270 | Loss: 0.2432\nBatch 200/270 | Loss: 0.4949\nBatch 210/270 | Loss: 0.3427\nBatch 220/270 | Loss: 0.1531\nBatch 230/270 | Loss: 0.3027\nBatch 240/270 | Loss: 0.4592\nBatch 250/270 | Loss: 0.1358\nBatch 260/270 | Loss: 0.2460\nBatch 270/270 | Loss: 0.1924\nEpoch 37 Loss: 0.3005 | Accuracy: 87.02%\n\nValidation Loss: 0.2495 | Validation Accuracy: 89.65%\n\nEpoch 38/50\n------------------------------\nBatch 10/270 | Loss: 0.2057\nBatch 20/270 | Loss: 0.2762\nBatch 30/270 | Loss: 0.2634\nBatch 40/270 | Loss: 0.3157\nBatch 50/270 | Loss: 0.1587\nBatch 60/270 | Loss: 0.1690\nBatch 70/270 | Loss: 0.3283\nBatch 80/270 | Loss: 0.3041\nBatch 90/270 | Loss: 0.3582\nBatch 100/270 | Loss: 0.3908\nBatch 110/270 | Loss: 0.4764\nBatch 120/270 | Loss: 0.2834\nBatch 130/270 | Loss: 0.3237\nBatch 140/270 | Loss: 0.2664\nBatch 150/270 | Loss: 0.4976\nBatch 160/270 | Loss: 0.3930\nBatch 170/270 | Loss: 0.3188\nBatch 180/270 | Loss: 0.2095\nBatch 190/270 | Loss: 0.1390\nBatch 200/270 | Loss: 0.2598\nBatch 210/270 | Loss: 0.1985\nBatch 220/270 | Loss: 0.2336\nBatch 230/270 | Loss: 0.2288\nBatch 240/270 | Loss: 0.2317\nBatch 250/270 | Loss: 0.4259\nBatch 260/270 | Loss: 0.2637\nBatch 270/270 | Loss: 0.3248\nEpoch 38 Loss: 0.2978 | Accuracy: 86.94%\n\nValidation Loss: 0.2825 | Validation Accuracy: 87.59%\n\nEpoch 39/50\n------------------------------\nBatch 10/270 | Loss: 0.1879\nBatch 20/270 | Loss: 0.3017\nBatch 30/270 | Loss: 0.2050\nBatch 40/270 | Loss: 0.2194\nBatch 50/270 | Loss: 0.3005\nBatch 60/270 | Loss: 0.4928\nBatch 70/270 | Loss: 0.2820\nBatch 80/270 | Loss: 0.2679\nBatch 90/270 | Loss: 0.1751\nBatch 100/270 | Loss: 0.3728\nBatch 110/270 | Loss: 0.3419\nBatch 120/270 | Loss: 0.1875\nBatch 130/270 | Loss: 0.2124\nBatch 140/270 | Loss: 0.3179\nBatch 150/270 | Loss: 0.3233\nBatch 160/270 | Loss: 0.2161\nBatch 170/270 | Loss: 0.1632\nBatch 180/270 | Loss: 0.2627\nBatch 190/270 | Loss: 0.1286\nBatch 200/270 | Loss: 0.2620\nBatch 210/270 | Loss: 0.2656\nBatch 220/270 | Loss: 0.1322\nBatch 230/270 | Loss: 0.3701\nBatch 240/270 | Loss: 0.5140\nBatch 250/270 | Loss: 0.3250\nBatch 260/270 | Loss: 0.1693\nBatch 270/270 | Loss: 0.3544\nEpoch 39 Loss: 0.2974 | Accuracy: 87.41%\n\nValidation Loss: 0.2425 | Validation Accuracy: 89.63%\n\nEpoch 40/50\n------------------------------\nBatch 10/270 | Loss: 0.2930\nBatch 20/270 | Loss: 0.1027\nBatch 30/270 | Loss: 0.2391\nBatch 40/270 | Loss: 0.2237\nBatch 50/270 | Loss: 0.3787\nBatch 60/270 | Loss: 0.4268\nBatch 70/270 | Loss: 0.2829\nBatch 80/270 | Loss: 0.2877\nBatch 90/270 | Loss: 0.2210\nBatch 100/270 | Loss: 0.1763\nBatch 110/270 | Loss: 0.2265\nBatch 120/270 | Loss: 0.2079\nBatch 130/270 | Loss: 0.4324\nBatch 140/270 | Loss: 0.2593\nBatch 150/270 | Loss: 0.1879\nBatch 160/270 | Loss: 0.2659\nBatch 170/270 | Loss: 0.2661\nBatch 180/270 | Loss: 0.2626\nBatch 190/270 | Loss: 0.3542\nBatch 200/270 | Loss: 0.2761\nBatch 210/270 | Loss: 0.3542\nBatch 220/270 | Loss: 0.2968\nBatch 230/270 | Loss: 0.2816\nBatch 240/270 | Loss: 0.3355\nBatch 250/270 | Loss: 0.3278\nBatch 260/270 | Loss: 0.3244\nBatch 270/270 | Loss: 0.2397\nEpoch 40 Loss: 0.2868 | Accuracy: 87.95%\n\nValidation Loss: 0.2375 | Validation Accuracy: 89.47%\n\nEpoch 41/50\n------------------------------\nBatch 10/270 | Loss: 0.1942\nBatch 20/270 | Loss: 0.3614\nBatch 30/270 | Loss: 0.3839\nBatch 40/270 | Loss: 0.3624\nBatch 50/270 | Loss: 0.2844\nBatch 60/270 | Loss: 0.1959\nBatch 70/270 | Loss: 0.2869\nBatch 80/270 | Loss: 0.3706\nBatch 90/270 | Loss: 0.4178\nBatch 100/270 | Loss: 0.2262\nBatch 110/270 | Loss: 0.3760\nBatch 120/270 | Loss: 0.3472\nBatch 130/270 | Loss: 0.4209\nBatch 140/270 | Loss: 0.2657\nBatch 150/270 | Loss: 0.2274\nBatch 160/270 | Loss: 0.4214\nBatch 170/270 | Loss: 0.6372\nBatch 180/270 | Loss: 0.2068\nBatch 190/270 | Loss: 0.4637\nBatch 200/270 | Loss: 0.1949\nBatch 210/270 | Loss: 0.2605\nBatch 220/270 | Loss: 0.3155\nBatch 230/270 | Loss: 0.1867\nBatch 240/270 | Loss: 0.1822\nBatch 250/270 | Loss: 0.2345\nBatch 260/270 | Loss: 0.3097\nBatch 270/270 | Loss: 0.2465\nEpoch 41 Loss: 0.2883 | Accuracy: 87.62%\n\nValidation Loss: 0.2429 | Validation Accuracy: 89.12%\n\nEpoch 42/50\n------------------------------\nBatch 10/270 | Loss: 0.2972\nBatch 20/270 | Loss: 0.1437\nBatch 30/270 | Loss: 0.3432\nBatch 40/270 | Loss: 0.2188\nBatch 50/270 | Loss: 0.1642\nBatch 60/270 | Loss: 0.1866\nBatch 70/270 | Loss: 0.1925\nBatch 80/270 | Loss: 0.2946\nBatch 90/270 | Loss: 0.3494\nBatch 100/270 | Loss: 0.3871\nBatch 110/270 | Loss: 0.2219\nBatch 120/270 | Loss: 0.3052\nBatch 130/270 | Loss: 0.4502\nBatch 140/270 | Loss: 0.1563\nBatch 150/270 | Loss: 0.2300\nBatch 160/270 | Loss: 0.2193\nBatch 170/270 | Loss: 0.2088\nBatch 180/270 | Loss: 0.3960\nBatch 190/270 | Loss: 0.2323\nBatch 200/270 | Loss: 0.3381\nBatch 210/270 | Loss: 0.1576\nBatch 220/270 | Loss: 0.4934\nBatch 230/270 | Loss: 0.3407\nBatch 240/270 | Loss: 0.2383\nBatch 250/270 | Loss: 0.3191\nBatch 260/270 | Loss: 0.2474\nBatch 270/270 | Loss: 0.1967\nEpoch 42 Loss: 0.2783 | Accuracy: 87.96%\n\nValidation Loss: 0.2343 | Validation Accuracy: 89.93%\n\nEpoch 43/50\n------------------------------\nBatch 10/270 | Loss: 0.1587\nBatch 20/270 | Loss: 0.3024\nBatch 30/270 | Loss: 0.2446\nBatch 40/270 | Loss: 0.4394\nBatch 50/270 | Loss: 0.4062\nBatch 60/270 | Loss: 0.1996\nBatch 70/270 | Loss: 0.3108\nBatch 80/270 | Loss: 0.4292\nBatch 90/270 | Loss: 0.3569\nBatch 100/270 | Loss: 0.1924\nBatch 110/270 | Loss: 0.3804\nBatch 120/270 | Loss: 0.1881\nBatch 130/270 | Loss: 0.2529\nBatch 140/270 | Loss: 0.2245\nBatch 150/270 | Loss: 0.2697\nBatch 160/270 | Loss: 0.3860\nBatch 170/270 | Loss: 0.4117\nBatch 180/270 | Loss: 0.2721\nBatch 190/270 | Loss: 0.3378\nBatch 200/270 | Loss: 0.1198\nBatch 210/270 | Loss: 0.4396\nBatch 220/270 | Loss: 0.2968\nBatch 230/270 | Loss: 0.3192\nBatch 240/270 | Loss: 0.3742\nBatch 250/270 | Loss: 0.3285\nBatch 260/270 | Loss: 0.1772\nBatch 270/270 | Loss: 0.5437\nEpoch 43 Loss: 0.2794 | Accuracy: 87.79%\n\nValidation Loss: 0.2228 | Validation Accuracy: 90.22%\n\nEpoch 44/50\n------------------------------\nBatch 10/270 | Loss: 0.3199\nBatch 20/270 | Loss: 0.2817\nBatch 30/270 | Loss: 0.2977\nBatch 40/270 | Loss: 0.1641\nBatch 50/270 | Loss: 0.2670\nBatch 60/270 | Loss: 0.3354\nBatch 70/270 | Loss: 0.3174\nBatch 80/270 | Loss: 0.3842\nBatch 90/270 | Loss: 0.1881\nBatch 100/270 | Loss: 0.2296\nBatch 110/270 | Loss: 0.2548\nBatch 120/270 | Loss: 0.1707\nBatch 130/270 | Loss: 0.3112\nBatch 140/270 | Loss: 0.4605\nBatch 150/270 | Loss: 0.2431\nBatch 160/270 | Loss: 0.2983\nBatch 170/270 | Loss: 0.2247\nBatch 180/270 | Loss: 0.2412\nBatch 190/270 | Loss: 0.5034\nBatch 200/270 | Loss: 0.1640\nBatch 210/270 | Loss: 0.2823\nBatch 220/270 | Loss: 0.2032\nBatch 230/270 | Loss: 0.4371\nBatch 240/270 | Loss: 0.4209\nBatch 250/270 | Loss: 0.3646\nBatch 260/270 | Loss: 0.2673\nBatch 270/270 | Loss: 0.4943\nEpoch 44 Loss: 0.2785 | Accuracy: 88.25%\n\nValidation Loss: 0.2361 | Validation Accuracy: 89.51%\n\nEpoch 45/50\n------------------------------\nBatch 10/270 | Loss: 0.2421\nBatch 20/270 | Loss: 0.1425\nBatch 30/270 | Loss: 0.2536\nBatch 40/270 | Loss: 0.1932\nBatch 50/270 | Loss: 0.2639\nBatch 60/270 | Loss: 0.3202\nBatch 70/270 | Loss: 0.1553\nBatch 80/270 | Loss: 0.1365\nBatch 90/270 | Loss: 0.4249\nBatch 100/270 | Loss: 0.1243\nBatch 110/270 | Loss: 0.1955\nBatch 120/270 | Loss: 0.1256\nBatch 130/270 | Loss: 0.2377\nBatch 140/270 | Loss: 0.2256\nBatch 150/270 | Loss: 0.1315\nBatch 160/270 | Loss: 0.1767\nBatch 170/270 | Loss: 0.3408\nBatch 180/270 | Loss: 0.1762\nBatch 190/270 | Loss: 0.2033\nBatch 200/270 | Loss: 0.3568\nBatch 210/270 | Loss: 0.3821\nBatch 220/270 | Loss: 0.3255\nBatch 230/270 | Loss: 0.3675\nBatch 240/270 | Loss: 0.5470\nBatch 250/270 | Loss: 0.1425\nBatch 260/270 | Loss: 0.2202\nBatch 270/270 | Loss: 0.3651\nEpoch 45 Loss: 0.2745 | Accuracy: 88.31%\n\nValidation Loss: 0.2155 | Validation Accuracy: 90.85%\n\nEpoch 46/50\n------------------------------\nBatch 10/270 | Loss: 0.3605\nBatch 20/270 | Loss: 0.1790\nBatch 30/270 | Loss: 0.1123\nBatch 40/270 | Loss: 0.2354\nBatch 50/270 | Loss: 0.2636\nBatch 60/270 | Loss: 0.6981\nBatch 70/270 | Loss: 0.2175\nBatch 80/270 | Loss: 0.5132\nBatch 90/270 | Loss: 0.2601\nBatch 100/270 | Loss: 0.2803\nBatch 110/270 | Loss: 0.2197\nBatch 120/270 | Loss: 0.2520\nBatch 130/270 | Loss: 0.2269\nBatch 140/270 | Loss: 0.1476\nBatch 150/270 | Loss: 0.2758\nBatch 160/270 | Loss: 0.5075\nBatch 170/270 | Loss: 0.2162\nBatch 180/270 | Loss: 0.2197\nBatch 190/270 | Loss: 0.3685\nBatch 200/270 | Loss: 0.3516\nBatch 210/270 | Loss: 0.2987\nBatch 220/270 | Loss: 0.1519\nBatch 230/270 | Loss: 0.2561\nBatch 240/270 | Loss: 0.2273\nBatch 250/270 | Loss: 0.2832\nBatch 260/270 | Loss: 0.1277\nBatch 270/270 | Loss: 0.2704\nEpoch 46 Loss: 0.2714 | Accuracy: 88.45%\n\nValidation Loss: 0.2183 | Validation Accuracy: 90.88%\n\nEpoch 47/50\n------------------------------\nBatch 10/270 | Loss: 0.2518\nBatch 20/270 | Loss: 0.3622\nBatch 30/270 | Loss: 0.1845\nBatch 40/270 | Loss: 0.1614\nBatch 50/270 | Loss: 0.2177\nBatch 60/270 | Loss: 0.1888\nBatch 70/270 | Loss: 0.3282\nBatch 80/270 | Loss: 0.2795\nBatch 90/270 | Loss: 0.2699\nBatch 100/270 | Loss: 0.0903\nBatch 110/270 | Loss: 0.1510\nBatch 120/270 | Loss: 0.2618\nBatch 130/270 | Loss: 0.4919\nBatch 140/270 | Loss: 0.1754\nBatch 150/270 | Loss: 0.3055\nBatch 160/270 | Loss: 0.2709\nBatch 170/270 | Loss: 0.2021\nBatch 180/270 | Loss: 0.2649\nBatch 190/270 | Loss: 0.3479\nBatch 200/270 | Loss: 0.1663\nBatch 210/270 | Loss: 0.1005\nBatch 220/270 | Loss: 0.1791\nBatch 230/270 | Loss: 0.1839\nBatch 240/270 | Loss: 0.1308\nBatch 250/270 | Loss: 0.1334\nBatch 260/270 | Loss: 0.3532\nBatch 270/270 | Loss: 0.0498\nEpoch 47 Loss: 0.2671 | Accuracy: 88.64%\n\nValidation Loss: 0.2308 | Validation Accuracy: 89.99%\n\nEpoch 48/50\n------------------------------\nBatch 10/270 | Loss: 0.2205\nBatch 20/270 | Loss: 0.2215\nBatch 30/270 | Loss: 0.2300\nBatch 40/270 | Loss: 0.2725\nBatch 50/270 | Loss: 0.2522\nBatch 60/270 | Loss: 0.3674\nBatch 70/270 | Loss: 0.1729\nBatch 80/270 | Loss: 0.1662\nBatch 90/270 | Loss: 0.3380\nBatch 100/270 | Loss: 0.2113\nBatch 110/270 | Loss: 0.3011\nBatch 120/270 | Loss: 0.3023\nBatch 130/270 | Loss: 0.2030\nBatch 140/270 | Loss: 0.4360\nBatch 150/270 | Loss: 0.3292\nBatch 160/270 | Loss: 0.2906\nBatch 170/270 | Loss: 0.3067\nBatch 180/270 | Loss: 0.1932\nBatch 190/270 | Loss: 0.1083\nBatch 200/270 | Loss: 0.3360\nBatch 210/270 | Loss: 0.2857\nBatch 220/270 | Loss: 0.3459\nBatch 230/270 | Loss: 0.3169\nBatch 240/270 | Loss: 0.2859\nBatch 250/270 | Loss: 0.4347\nBatch 260/270 | Loss: 0.1915\nBatch 270/270 | Loss: 0.2272\nEpoch 48 Loss: 0.2695 | Accuracy: 88.56%\n\nValidation Loss: 0.2172 | Validation Accuracy: 91.18%\n\nEpoch 49/50\n------------------------------\nBatch 10/270 | Loss: 0.1964\nBatch 20/270 | Loss: 0.2557\nBatch 30/270 | Loss: 0.3571\nBatch 40/270 | Loss: 0.2518\nBatch 50/270 | Loss: 0.2578\nBatch 60/270 | Loss: 0.1188\nBatch 70/270 | Loss: 0.3013\nBatch 80/270 | Loss: 0.3400\nBatch 90/270 | Loss: 0.2373\nBatch 100/270 | Loss: 0.2910\nBatch 110/270 | Loss: 0.2799\nBatch 120/270 | Loss: 0.2087\nBatch 130/270 | Loss: 0.4035\nBatch 140/270 | Loss: 0.5123\nBatch 150/270 | Loss: 0.3262\nBatch 160/270 | Loss: 0.2411\nBatch 170/270 | Loss: 0.3140\nBatch 180/270 | Loss: 0.1909\nBatch 190/270 | Loss: 0.2109\nBatch 200/270 | Loss: 0.2422\nBatch 210/270 | Loss: 0.1665\nBatch 220/270 | Loss: 0.2055\nBatch 230/270 | Loss: 0.4041\nBatch 240/270 | Loss: 0.1715\nBatch 250/270 | Loss: 0.3103\nBatch 260/270 | Loss: 0.2808\nBatch 270/270 | Loss: 0.1352\nEpoch 49 Loss: 0.2697 | Accuracy: 88.46%\n\nValidation Loss: 0.2159 | Validation Accuracy: 90.76%\n\nEpoch 50/50\n------------------------------\nBatch 10/270 | Loss: 0.1928\nBatch 20/270 | Loss: 0.1282\nBatch 30/270 | Loss: 0.3339\nBatch 40/270 | Loss: 0.2597\nBatch 50/270 | Loss: 0.3625\nBatch 60/270 | Loss: 0.4514\nBatch 70/270 | Loss: 0.2404\nBatch 80/270 | Loss: 0.2018\nBatch 90/270 | Loss: 0.2804\nBatch 100/270 | Loss: 0.1124\nBatch 110/270 | Loss: 0.1517\nBatch 120/270 | Loss: 0.1847\nBatch 130/270 | Loss: 0.4906\nBatch 140/270 | Loss: 0.2423\nBatch 150/270 | Loss: 0.1485\nBatch 160/270 | Loss: 0.2026\nBatch 170/270 | Loss: 0.2817\nBatch 180/270 | Loss: 0.3366\nBatch 190/270 | Loss: 0.2165\nBatch 200/270 | Loss: 0.2569\nBatch 210/270 | Loss: 0.5012\nBatch 220/270 | Loss: 0.1875\nBatch 230/270 | Loss: 0.1511\nBatch 240/270 | Loss: 0.2760\nBatch 250/270 | Loss: 0.4090\nBatch 260/270 | Loss: 0.2471\nBatch 270/270 | Loss: 0.0383\nEpoch 50 Loss: 0.2673 | Accuracy: 88.56%\n\nValidation Loss: 0.2163 | Validation Accuracy: 91.00%\n\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def evaluate_model(model, dataloader, criterion):\n    model.eval()\n    total = 0\n    correct = 0\n    running_loss = 0.0\n    \n    with torch.no_grad():\n        for inputs, labels in dataloader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += labels.size(0)\n            correct += predicted.eq(labels).sum().item()\n    \n    test_loss = running_loss / len(dataloader)\n    test_acc = 100. * correct / total\n    print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_acc:.2f}%\")\n\nevaluate_model(model, dataloaders['test'], criterion)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T15:51:39.204213Z","iopub.execute_input":"2025-03-22T15:51:39.204535Z","iopub.status.idle":"2025-03-22T15:52:19.825713Z","shell.execute_reply.started":"2025-03-22T15:51:39.204509Z","shell.execute_reply":"2025-03-22T15:52:19.824767Z"}},"outputs":[{"name":"stdout","text":"Test Loss: 0.2220 | Test Accuracy: 90.47%\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"torch.save(model.state_dict(), \"glaucoma_model_90TA.pth\")\nprint(\"Model saved successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T15:54:18.374100Z","iopub.execute_input":"2025-03-22T15:54:18.374403Z","iopub.status.idle":"2025-03-22T15:54:18.920017Z","shell.execute_reply.started":"2025-03-22T15:54:18.374380Z","shell.execute_reply":"2025-03-22T15:54:18.919275Z"}},"outputs":[{"name":"stdout","text":"Model saved successfully!\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}